<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Artem Kazakov Kozlov — AI Engineer Portfolio</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      background: #f9f9f9;
      color: #333;
    }
    h1, h2, h3 {
      color: #222;
    }
    ul {
      margin-left: 20px;
    }
    a {
      color: #007acc;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    code {
      background-color: #eee;
      padding: 2px 6px;
      border-radius: 4px;
    }
    hr {
      margin: 40px 0;
    }
    details {
      background: white;
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 15px;
      margin-bottom: 15px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.05);
      transition: all 0.3s ease;
    }
    summary {
      font-weight: bold;
      font-size: 18px;
      cursor: pointer;
      outline: none;
    }
    details[open] {
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    details ul {
      margin-top: 10px;
    }
  </style>
</head>
<body>

  <h1>Hi, I'm Artem</h1>

  <h3>Specialization</h3>
  <ul>
    <li>Multi-agent systems for automating complex workflows</li>
    <li>Fine-tuning LLMs for domain-specific tasks</li>
    <li>Prompt engineering with evaluation & safety guardrails</li>
    <li>Building intelligent AI applications</li>
    <li>Models: Claude, GPT, Gemma, etc.</li>
  </ul>

  <h3>Tech Stack</h3>
  <ul>
    <li>Languages: Python</li>
    <li>Frameworks: LangChain, FastAPI, Gradio</li>
    <li>NLP Tools: Hugging Face, spaCy, Vector DBs</li>
    <li>Infra: Docker, API design, LLM Ops</li>
  </ul>

  <h3>Contact</h3>
  <ul>
    <li>Email: <a href="mailto:KazKozDev@gmail.com">KazKozDev@gmail.com</a></li>
    <li>LinkedIn: <a href="https://linkedin.com/in/kazkozdev" target="_blank">linkedin.com/in/kazkozdev</a></li>
  </ul>

  <p><code>llm-engineering</code> <code>prompt-engineering</code> <code>fine-tuning</code> <code>multi-agent</code> <code>huggingface</code> <code>ai-automation</code></p>

  <hr>

  <h2>Chatbots</h2>

  <details>
    <summary>VerbaBot Public</summary>
    <ul>
      <li>Local LLM deployment with complete data privacy</li>
      <li>Advanced RAG pipeline (multi-format document retrieval)</li>
      <li>Personal memory system across sessions</li>
      <li>Calendar integration via natural language</li>
      <li>Dynamic model switching (Ollama interface)</li>
    </ul>
  </details>

  <details>
    <summary>QuéAI</summary>
    <ul>
      <li>Hybrid search: vector similarity + BM25</li>
      <li>Image and text-based product search</li>
      <li>Adaptive user profiles via SQLite storage</li>
      <li>Local inference using Gemma 3:12B</li>
      <li>Intelligent caching for performance optimization</li>
    </ul>
  </details>

  <details>
    <summary>Researchify</summary>
    <ul>
      <li>Natural language search over academic databases</li>
      <li>Scientific paper summarization and key insights extraction</li>
      <li>Citation network and impact analysis</li>
      <li>Document parsing (PDF, DOCX, TXT, CSV)</li>
      <li>Trend identification in research domains</li>
    </ul>
  </details>

  <hr>

  <h2>Agents</h2>

  <details>
    <summary>LLMFlow</summary>
    <ul>
      <li>Chain orchestration for multi-tool task execution</li>
      <li>Modular tool system (weather, news, web search, finance, astronomy, etc.)</li>
      <li>Local deployment with Ollama and Gemma 3:12B model</li>
      <li>Real-time data access via Open APIs (Open-Meteo, DuckDuckGo, RSS feeds)</li>
      <li>Optimized conversation memory with multilingual support</li>
      <li>Extensible architecture for adding custom tools and LLMs</li>
      <li>CLI interface for interactive testing and prototyping</li>
    </ul>
  </details>

  <details>
    <summary>Multi-Expert LLM Consensus (MELC)</summary>
    <ul>
      <li>Asynchronous parallel processing of queries (asyncio-based)</li>
      <li>Critical cross-validation by dedicated critique agent</li>
      <li>Consensus synthesis with iterative refinement</li>
      <li>Confidence scoring for each expert response</li>
      <li>RESTful API communication layer</li>
      <li>Scalable and fault-tolerant architecture</li>
    </ul>
  </details>

  <hr>

  <h2>Tools & Platforms</h2>

  <details>
    <summary>Multimodal Prompt Studio</summary>
    <ul>
      <li>Multimodal prompt editor (text, image, audio)</li>
      <li>A/B testing and prompt versioning with rollback support</li>
      <li>Analytics on token usage, latency, and output quality</li>
      <li>Template library for reusable prompt patterns</li>
      <li>RAG-ready document management system</li>
      <li>Microservices architecture: React + FastAPI + PostgreSQL</li>
      <li>Dockerized deployment with local API access</li>
    </ul>
  </details>

  <details>
    <summary>DeepChain Refinement System</summary>
    <ul>
      <li>Three-stage refinement: analysis, context-aware enhancement, and synthesis</li>
      <li>Chain-of-thought reasoning applied across iterations</li>
      <li>Hallucination reduction and fact verification</li>
      <li>Designed for enhancing compact models (e.g., Gemma2:9B)</li>
      <li>Lightweight Python architecture (async-ready)</li>
      <li>Runs locally with Ollama integration</li>
    </ul>
  </details>

  <details>
    <summary>Net Reflective Reasoning</summary>
    <ul>
      <li>Multi-stage reasoning pipeline: intent → search → critique → synthesis</li>
      <li>Real-time web search with smart query reformulation</li>
      <li>Reflective critique and refinement mechanisms</li>
      <li>Confidence scoring and fallback strategies</li>
      <li>Fully asynchronous architecture with caching</li>
      <li>Local LLM execution with Gemma2:9B via Ollama</li>
    </ul>
  </details>

</body>
</html>
